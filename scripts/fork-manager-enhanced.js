#!/usr/bin/env node

/**
 * Enhanced Fork Manager
 *
 * This script provides a comprehensive forking system that:
 * 1. Creates GitHub repositories
 * 2. Deploys to Vercel automatically
 * 3. Sets up databases and cache
 * 4. Configures custom domains
 * 5. Manages environment variables
 * 6. Tracks all deployments
 *
 * Usage: node scripts/fork-manager-enhanced.js <command> [options]
 */

const fs = require('fs');
const path = require('path');
const { execSync } = require('child_process');
require('dotenv').config();

class EnhancedForkManager {
  constructor() {
    this.githubToken = process.env.GITHUB_TOKEN;
    this.vercelToken = process.env.VERCEL_TOKEN;
    this.vercelOrgId = process.env.VERCEL_ORG_ID;
    this.databaseUrl = process.env.POSTGRES_URL;

    if (!this.githubToken || !this.vercelToken) {
      console.error('‚ùå Missing required tokens. Please set GITHUB_TOKEN and VERCEL_TOKEN in .env');
      process.exit(1);
    }
  }

  // Create a complete fork with full automation
  async createCompleteFork(config) {
    console.log(`üöÄ Creating complete fork: ${config.name}`);

    try {
      const result = {
        name: config.name,
        startTime: Date.now(),
        steps: []
      };

      // Step 1: Create GitHub repository
      console.log('üìÇ Creating GitHub repository...');
      const repo = await this.createGitHubRepo(config);
      result.steps.push({ step: 'github_repo', status: 'success', url: repo.html_url });
      console.log(`‚úÖ GitHub repo created: ${repo.html_url}`);

      // Step 2: Copy and customize code
      console.log('üìù Copying and customizing code...');
      await this.copyAndCustomizeCode(repo, config);
      result.steps.push({ step: 'code_customization', status: 'success' });
      console.log('‚úÖ Code customized');

      // Step 3: Push code to GitHub
      console.log('üì§ Pushing code to GitHub...');
      await this.pushCodeToGitHub(repo, config);
      result.steps.push({ step: 'code_push', status: 'success' });
      console.log('‚úÖ Code pushed to GitHub');

      // Step 4: Deploy to Vercel
      console.log('üåê Deploying to Vercel...');
      const deployment = await this.deployToVercel(repo, config);
      result.steps.push({ step: 'vercel_deployment', status: 'success', url: deployment.url });
      console.log(`‚úÖ Deployed to Vercel: ${deployment.url}`);

      // Step 5: Set up database
      console.log('üóÑÔ∏è Setting up database...');
      const database = await this.setupDatabase(config);
      result.steps.push({ step: 'database_setup', status: 'success', database: database.name });
      console.log('‚úÖ Database configured');

      // Step 6: Configure environment variables
      console.log('üîê Configuring environment variables...');
      await this.setupEnvironmentVariables(deployment, config, database);
      result.steps.push({ step: 'environment_setup', status: 'success' });
      console.log('‚úÖ Environment variables configured');

      // Step 7: Set up custom domain (if provided)
      if (config.domain) {
        console.log('üåç Setting up custom domain...');
        await this.setupCustomDomain(deployment, config);
        result.steps.push({ step: 'domain_setup', status: 'success', domain: config.domain });
        console.log(`‚úÖ Custom domain configured: ${config.domain}`);
      }

      // Step 8: Initialize monitoring
      console.log('üìä Initializing monitoring...');
      await this.setupMonitoring(config, deployment);
      result.steps.push({ step: 'monitoring_setup', status: 'success' });
      console.log('‚úÖ Monitoring configured');

      // Step 9: Create deployment documentation
      console.log('üìö Creating documentation...');
      await this.createDocumentation(config, result);
      result.steps.push({ step: 'documentation', status: 'success' });
      console.log('‚úÖ Documentation created');

      result.totalTime = Date.now() - result.startTime;
      result.status = 'success';
      result.deploymentUrl = deployment.url;
      result.customDomain = config.domain;

      // Save deployment record
      await this.saveDeploymentRecord(result);

      console.log('\\nüéâ Fork created successfully!');
      console.log(`\\nüìã Summary:`);
      console.log(`   Name: ${config.name}`);
      console.log(`   GitHub: ${repo.html_url}`);
      console.log(`   Deployment: ${deployment.url}`);
      if (config.domain) console.log(`   Custom Domain: https://${config.domain}`);
      console.log(`   Total Time: ${Math.round(result.totalTime / 1000)}s`);

      return result;

    } catch (error) {
      console.error('‚ùå Fork creation failed:', error.message);
      throw error;
    }
  }

  // Create GitHub repository
  async createGitHubRepo(config) {
    const repoName = config.name.toLowerCase().replace(/[^a-z0-9]/g, '-');

    const response = await fetch('https://api.github.com/user/repos', {
      method: 'POST',
      headers: {
        'Authorization': `token ${this.githubToken}`,
        'Content-Type': 'application/json',
        'User-Agent': 'Forkable-AI-Framework'
      },
      body: JSON.stringify({
        name: repoName,
        description: `${config.name} - AI Image Processing Application`,
        private: false,
        auto_init: false,
        has_issues: true,
        has_projects: true,
        has_wiki: false
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`GitHub API error: ${response.status} - ${errorText}`);
    }

    return await response.json();
  }

  // Copy and customize code for the fork
  async copyAndCustomizeCode(repo, config) {
    const tempDir = path.join(__dirname, '../temp', repo.name);

    // Create temporary directory
    if (fs.existsSync(tempDir)) {
      execSync(`rm -rf ${tempDir}`, { stdio: 'pipe' });
    }
    fs.mkdirSync(tempDir, { recursive: true });

    // Copy source files
    execSync(`cp -r ${path.join(__dirname, '..')}/* ${tempDir}/`, { stdio: 'pipe' });

    // Remove unnecessary files
    const filesToRemove = [
      'temp', 'forks', 'examples', 'planning', 'memory', 'specs',
      '.git', 'node_modules', '.env', '.env.local', 'mydatabase.db'
    ];

    filesToRemove.forEach(file => {
      const filePath = path.join(tempDir, file);
      if (fs.existsSync(filePath)) {
        execSync(`rm -rf "${filePath}"`, { stdio: 'pipe' });
      }
    });

    // Customize server.js with the new prompt
    const serverPath = path.join(tempDir, 'backend/server-enhanced.js');
    let serverContent = fs.readFileSync(serverPath, 'utf8');

    // Replace the gemini prompt
    const promptRegex = /const geminiPrompt = ".*?";/;
    serverContent = serverContent.replace(promptRegex, `const geminiPrompt = "${config.prompt}";`);

    fs.writeFileSync(serverPath, serverContent);

    // Update package.json
    const packagePath = path.join(tempDir, 'package.json');
    const packageJson = JSON.parse(fs.readFileSync(packagePath, 'utf8'));
    packageJson.name = repo.name;
    packageJson.description = `${config.name} - AI Image Processing Application`;
    fs.writeFileSync(packagePath, JSON.stringify(packageJson, null, 2));

    // Update vercel.json
    const vercelPath = path.join(tempDir, 'vercel.json');
    const vercelConfig = JSON.parse(fs.readFileSync(vercelPath, 'utf8'));
    vercelConfig.name = repo.name;
    fs.writeFileSync(vercelPath, JSON.stringify(vercelConfig, null, 2));

    // Create custom README
    const readmeContent = `# ${config.name}

${config.description || `${config.name} is an AI-powered image processing application.`}

## Features

- AI-powered image processing: "${config.prompt}"
- Professional-grade results
- Easy-to-use interface
- Scalable infrastructure
- Real-time monitoring

## Deployment

This application is automatically deployed using:

- **Frontend & Backend**: Vercel
- **Database**: Vercel Postgres
- **Cache**: Vercel KV
- **Monitoring**: Sentry + Custom Dashboard

## Environment Variables

Required environment variables:

\`\`\`
GEMINI_API_KEY=your_gemini_api_key
POSTGRES_URL=your_postgres_url
KV_REST_API_URL=your_kv_url
KV_REST_API_TOKEN=your_kv_token
SENTRY_DSN=your_sentry_dsn
\`\`\`

## API Endpoints

- \`GET /health\` - Health check
- \`POST /api/process-image\` - Process image with AI
- \`GET /api/metrics\` - Performance metrics

## Tech Stack

- **Backend**: Node.js + Express
- **Database**: PostgreSQL
- **Cache**: Redis (Vercel KV)
- **Deployment**: Vercel
- **Monitoring**: Sentry + Custom Analytics

## License

MIT License
`;

    fs.writeFileSync(path.join(tempDir, 'README.md'), readmeContent);

    return tempDir;
  }

  // Push code to GitHub
  async pushCodeToGitHub(repo, config) {
    const tempDir = path.join(__dirname, '../temp', repo.name);

    // Initialize git repository
    process.chdir(tempDir);
    execSync('git init', { stdio: 'pipe' });
    execSync('git add .', { stdio: 'pipe' });
    execSync(`git commit -m "Initial commit for ${config.name}"`, { stdio: 'pipe' });
    execSync(`git remote add origin ${repo.ssh_url}`, { stdio: 'pipe' });
    execSync('git push -u origin main', { stdio: 'pipe' });

    // Clean up temp directory
    process.chdir(path.join(__dirname, '..'));
    execSync(`rm -rf ${tempDir}`, { stdio: 'pipe' });
  }

  // Deploy to Vercel
  async deployToVercel(repo, config) {
    const response = await fetch('https://api.vercel.com/v13/deployments', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.vercelToken}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        name: repo.name,
        gitSource: {
          type: 'github',
          repo: repo.full_name,
          ref: 'main'
        },
        projectSettings: {
          framework: 'other',
          buildCommand: 'npm run build',
          outputDirectory: 'dist'
        },
        target: 'production'
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Vercel deployment failed: ${response.status} - ${errorText}`);
    }

    return await response.json();
  }

  // Set up database for the fork
  async setupDatabase(config) {
    // In a real implementation, this would create a separate database
    // For now, we'll use a shared database with proper isolation

    const dbName = config.name.toLowerCase().replace(/[^a-z0-9]/g, '_');

    return {
      name: dbName,
      url: this.databaseUrl, // In production, create separate DB
      schema: 'public'
    };
  }

  // Configure environment variables in Vercel
  async setupEnvironmentVariables(deployment, config, database) {
    const envVars = [
      { key: 'GEMINI_API_KEY', value: process.env.GEMINI_API_KEY },
      { key: 'POSTGRES_URL', value: database.url },
      { key: 'KV_REST_API_URL', value: process.env.KV_REST_API_URL },
      { key: 'KV_REST_API_TOKEN', value: process.env.KV_REST_API_TOKEN },
      { key: 'NODE_ENV', value: 'production' },
      { key: 'SENTRY_DSN', value: process.env.SENTRY_DSN },
      { key: 'ENABLE_CACHE', value: 'true' },
      { key: 'AUTO_MIGRATE', value: 'false' }
    ];

    for (const envVar of envVars) {
      if (envVar.value) {
        await fetch(`https://api.vercel.com/v9/projects/${deployment.projectId}/env`, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${this.vercelToken}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            key: envVar.key,
            value: envVar.value,
            type: 'encrypted',
            target: ['production', 'preview']
          })
        });
      }
    }
  }

  // Set up custom domain
  async setupCustomDomain(deployment, config) {
    if (!config.domain) return;

    const response = await fetch(`https://api.vercel.com/v9/projects/${deployment.projectId}/domains`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.vercelToken}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        name: config.domain
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.warn(`Domain setup warning: ${errorText}`);
    }
  }

  // Set up monitoring
  async setupMonitoring(config, deployment) {
    // This would integrate with monitoring services
    console.log(`Setting up monitoring for ${config.name}`);

    // In a real implementation:
    // 1. Create Sentry project
    // 2. Set up uptime monitoring
    // 3. Configure alerts
    // 4. Set up analytics tracking
  }

  // Create deployment documentation
  async createDocumentation(config, result) {
    const docsDir = path.join(__dirname, '../deployments');
    if (!fs.existsSync(docsDir)) {
      fs.mkdirSync(docsDir, { recursive: true });
    }

    const deploymentDoc = {
      name: config.name,
      created: new Date().toISOString(),
      config: config,
      result: result,
      urls: {
        github: result.steps.find(s => s.step === 'github_repo')?.url,
        deployment: result.deploymentUrl,
        customDomain: config.domain ? `https://${config.domain}` : null
      },
      monitoring: {
        health: `${result.deploymentUrl}/health`,
        metrics: `${result.deploymentUrl}/api/metrics`
      }
    };

    fs.writeFileSync(
      path.join(docsDir, `${config.name.toLowerCase().replace(/[^a-z0-9]/g, '-')}.json`),
      JSON.stringify(deploymentDoc, null, 2)
    );
  }

  // Save deployment record
  async saveDeploymentRecord(result) {
    const recordsFile = path.join(__dirname, '../deployment-records.json');
    let records = [];

    if (fs.existsSync(recordsFile)) {
      records = JSON.parse(fs.readFileSync(recordsFile, 'utf8'));
    }

    records.push({
      ...result,
      timestamp: new Date().toISOString()
    });

    fs.writeFileSync(recordsFile, JSON.stringify(records, null, 2));
  }

  // List all deployments
  listDeployments() {
    const recordsFile = path.join(__dirname, '../deployment-records.json');

    if (!fs.existsSync(recordsFile)) {
      console.log('No deployments found.');
      return;
    }

    const records = JSON.parse(fs.readFileSync(recordsFile, 'utf8'));

    console.log(`\\nüìã Deployment Records (${records.length} total):\\n`);

    records.forEach((record, index) => {
      console.log(`${index + 1}. ${record.name}`);
      console.log(`   Status: ${record.status}`);
      console.log(`   Created: ${new Date(record.timestamp).toLocaleDateString()}`);
      console.log(`   URL: ${record.deploymentUrl}`);
      if (record.customDomain) {
        console.log(`   Domain: https://${record.customDomain}`);
      }
      console.log(`   Time: ${Math.round(record.totalTime / 1000)}s`);
      console.log('');
    });
  }
}

// CLI Interface
async function main() {
  const args = process.argv.slice(2);
  const command = args[0];

  const forkManager = new EnhancedForkManager();

  switch (command) {
    case 'create':
      if (args.length < 4) {
        console.error('Usage: node fork-manager-enhanced.js create <name> <prompt> <domain> [description]');
        process.exit(1);
      }

      const [, name, prompt, domain, description] = args;
      const config = {
        name,
        prompt,
        domain: domain === 'none' ? null : domain,
        description
      };

      try {
        await forkManager.createCompleteFork(config);
      } catch (error) {
        console.error('‚ùå Failed to create fork:', error.message);
        process.exit(1);
      }
      break;

    case 'list':
      forkManager.listDeployments();
      break;

    default:
      console.log(`
üöÄ Enhanced Fork Manager

Commands:
  create <name> <prompt> <domain> [description]  - Create a complete fork
  list                                           - List all deployments

Examples:
  node fork-manager-enhanced.js create "Sketchify" "Convert to pencil sketch" "sketchify.com" "AI sketch converter"
  node fork-manager-enhanced.js create "PhotoCartoon" "Make cartoon style" "none" "Cartoon photo converter"
  node fork-manager-enhanced.js list

Environment Variables Required:
  GITHUB_TOKEN     - GitHub personal access token
  VERCEL_TOKEN     - Vercel API token
  VERCEL_ORG_ID    - Vercel organization ID
  POSTGRES_URL     - Database connection string
  GEMINI_API_KEY   - Google Gemini API key
      `);
      break;
  }
}

// Run the CLI
if (require.main === module) {
  main().catch(error => {
    console.error('Fatal error:', error);
    process.exit(1);
  });
}

module.exports = EnhancedForkManager;